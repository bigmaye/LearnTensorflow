{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XOR Problem with tensorflow\n",
    "Original tutorial: https://aimatters.wordpress.com/2016/01/16/solving-xor-with-a-neural-network-in-tensorflow/\n",
    "Create a 3 layer neural network (Input, Hidden, Output) to solve the XOR problem\n",
    "Complete source code tutorial here: https://github.com/StephenOman/TensorFlowExamples/blob/master/xor%20nn/xor_nn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import tensor flow and time libraries\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "XOR_X = [[0,0],[0,1],[1,0],[1,1]]\n",
    "XOR_Y = [[0],[1],[1],[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare variables to receive imput data\n",
    "Next step is to set up placeholders to hold the input data. TensorFlow will automatically fill them with the data when we run the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_ = tf.placeholder(tf.float32, shape=[4,2], name=\"x-input\")\n",
    "y_ = tf.placeholder(tf.float32, shape=[4,1], name=\"y-input\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Theta1 = tf.Variable(tf.random_uniform([2,2], -1, 1), name=\"Theta1\")\n",
    "Theta2 = tf.Variable(tf.random_uniform([2,1], -1, 1), name=\"Theta2\")\n",
    "Bias1 = tf.Variable(tf.zeros([2]), name=\"Bias1\")\n",
    "Bias2 = tf.Variable(tf.zeros([1]), name=\"Bias2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# First layer (with activations)\n",
    "A2 = tf.sigmoid(tf.matmul(x_, Theta1) + Bias1)\n",
    "\n",
    "# Second layer (Also with activations)\n",
    "Hypothesis = tf.sigmoid(tf.matmul(A2, Theta2) + Bias2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a cost function\n",
    "On this case we're doing a cross-entropy cost function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cost = tf.reduce_mean(( (y_ * tf.log(Hypothesis)) + \n",
    "        ((1 - y_) * tf.log(1.0 - Hypothesis)) ) * -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_loss = tf.scalar_summary(cost.op.name, cost)\n",
    "summary_op = tf.merge_all_summaries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "Here we're going to use Gradient descent. What this statement says is that weâ€™re going to use GradientDescentOptimizer as our training algorithm, the learning rate (alpha from before) is going to be 0.01 and we want to minimize the cost function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(0.01).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()\n",
    "sess = tf.Session()\n",
    "# Output model to tensorboard\n",
    "writer = tf.train.SummaryWriter(\"./logs/xor_logs\", sess.graph)\n",
    "# Old version gives a warning\n",
    "#writer = tf.train.SummaryWriter(\"./logs/xor_logs\", sess.graph_def)\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch ', 0)\n",
      "('Hypothesis ', array([[ 0.408326  ],\n",
      "       [ 0.43239149],\n",
      "       [ 0.40718734],\n",
      "       [ 0.43138522]], dtype=float32))\n",
      "('Theta1 ', array([[-0.13445616,  0.00433019],\n",
      "       [ 0.90191185, -0.35367614]], dtype=float32))\n",
      "('Bias1 ', array([  1.93600081e-05,  -1.69980209e-04], dtype=float32))\n",
      "('Theta2 ', array([[ 0.112869  ],\n",
      "       [-0.85633242]], dtype=float32))\n",
      "('Bias2 ', array([ 0.00080494], dtype=float32))\n",
      "('cost ', 0.70656431)\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'feed_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-18c998d6ae3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Bias2 '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBias2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cost '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mXOR_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mXOR_Y\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0msummary_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_op\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m             \u001b[0msummary_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_summary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msummary_str\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mt_end\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'feed_dict' is not defined"
     ]
    }
   ],
   "source": [
    "t_start = time.clock()\n",
    "for i in range(100000):\n",
    "        # Run the training step here\n",
    "        sess.run(train_step, feed_dict={x_: XOR_X, y_: XOR_Y})\n",
    "        # Display some information\n",
    "        if i % 50000 == 0:\n",
    "            print('Epoch ', i)\n",
    "            print('Hypothesis ', sess.run(Hypothesis, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "            print('Theta1 ', sess.run(Theta1))\n",
    "            print('Bias1 ', sess.run(Bias1))\n",
    "            print('Theta2 ', sess.run(Theta2))\n",
    "            print('Bias2 ', sess.run(Bias2))\n",
    "            print('cost ', sess.run(cost, feed_dict={x_: XOR_X, y_: XOR_Y}))\n",
    "            #summary_str = sess.run(summary_op, feed_dict=feed_dict)\n",
    "            #summary_writer.add_summary(summary_str, step)\n",
    "t_end = time.clock()\n",
    "print('Elapsed time ', t_end - t_start)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
